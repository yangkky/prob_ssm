{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests for mod_mod algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import distributions as dist\n",
    "\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style('white')\n",
    "sns.set_context('paper')\n",
    "# Plot adjustments:\n",
    "plt.rcParams.update({'ytick.labelsize': 15})\n",
    "plt.rcParams.update({'xtick.labelsize': 15})\n",
    "plt.rcParams.update({'axes.labelsize': 35})\n",
    "plt.rcParams.update({'legend.fontsize': 30})\n",
    "plt.rcParams.update({'axes.titlesize': 16})\n",
    "\n",
    "from gptorch import kernels, models\n",
    "import helpers, opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../inputs/phoq.pkl', 'rb') as f:\n",
    "    t = pickle.load(f)\n",
    "\n",
    "X = t[0] # one-hot encoding of X\n",
    "T = t[1] # tokenized encoding of X\n",
    "y = t[2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500 of 500\tNLML: 37.3695\tsn: 0.179452\t"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "rand_inds = np.random.choice(len(X), 100, replace=True) # generate random indices for 100 X's to sample from\n",
    "X_train = X[rand_inds]\n",
    "y_train = y[rand_inds]\n",
    "X_test = X\n",
    "y_true = y\n",
    "\n",
    "dic, means = helpers.get_predictions(X_train, y_train, X_test, its=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aas = 'ARNDCQEGHILKMFPSTWYV'\n",
    "ground = [(aa, i) for aa in aas for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_X = 35\n",
    "len_center = 5\n",
    "\n",
    "np.random.seed(1)\n",
    "X = np.random.choice(len(ground), len_X, replace=False)\n",
    "X = [ground[x] for x in X]\n",
    "\n",
    "np.random.seed(12)\n",
    "center = np.random.choice(len(ground), len_center, replace=False)\n",
    "center = [ground[c] for c in center]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = helpers.get_seed(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perm = opt.make_perm(ground, center)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1. Tests for modular upper bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure upper bound is indeed upper bound\n",
    "\n",
    "# obj_LHS\n",
    "obj_left = opt.obj_LHS(X, 4, dic)\n",
    "obj_left_upper = opt.mod_upper(X, opt.obj_LHS, center, 4, dic)\n",
    "assert obj_left_upper > obj_left \n",
    "\n",
    "# obj_RHS\n",
    "obj_right = opt.obj_RHS(X, 4, dic, 100)\n",
    "obj_right_upper = opt.mod_upper(X, opt.obj_RHS, center, 4, dic, 100)\n",
    "assert obj_right_upper > obj_right\n",
    "\n",
    "# check tightness?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure modular upper bound is modular\n",
    "\n",
    "# obj_LHS\n",
    "mod_up1 = torch.stack([opt.mod_upper([x], opt.obj_LHS, center, 4, dic) for x in X]).sum()\n",
    "mod_up1 -= (len(X) - 1) * opt.mod_upper([], opt.obj_LHS, center, 4, dic) # empty set\n",
    "assert np.isclose(np.array(obj_left_upper), np.array(mod_up1))\n",
    "\n",
    "# obj_RHS\n",
    "mod_up2 = torch.stack([opt.mod_upper([x], opt.obj_RHS, center, 4, dic, 100) for x in X]).sum()\n",
    "mod_up2 -= (len(X) - 1) * opt.mod_upper([], opt.obj_RHS, center, 4, dic, 100) # empty set\n",
    "assert np.isclose(np.array(obj_right_upper), np.array(mod_up2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure when X is passed in as center, obj is returned\n",
    "\n",
    "# obj_LHS\n",
    "assert obj_left == opt.mod_upper(X, opt.obj_LHS, X, 4, dic) \n",
    "\n",
    "# obj_RHS\n",
    "assert obj_right == opt.mod_upper(X, opt.obj_RHS, X, 4, dic, 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. Tests for modular lower bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure lower bound is indeed lower bound\n",
    "\n",
    "# obj_LHS\n",
    "obj_left_lower = opt.mod_lower(X, opt.obj_LHS, perm, 4, dic)\n",
    "assert obj_left_lower < obj_left \n",
    "\n",
    "# obj_RHS\n",
    "obj_right_lower = opt.mod_lower(X, opt.obj_RHS, perm, 4, dic, 100)\n",
    "assert obj_right_lower < obj_right \n",
    "\n",
    "# check tightness?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make sure modular lower bound is modular\n",
    "\n",
    "# obj_LHS\n",
    "mod_down1 = torch.stack([opt.mod_lower([x], opt.obj_LHS, perm, 4, dic) for x in X]).sum()\n",
    "assert np.isclose(np.array(obj_left_lower), np.array(mod_down1))\n",
    "\n",
    "# obj_RHS\n",
    "mod_down2 = torch.stack([opt.mod_lower([x], opt.obj_RHS, perm, 4, dic, 100) for x in X]).sum()\n",
    "assert np.isclose(np.array(obj_right_lower), np.array(mod_down2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lib, obj_lst = opt.mod_mod(ground, opt.obj_LHS, opt.obj_RHS, X, fn_args=(4, dic), g_args=(4, dic, 100), verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that cant add or take away anything to increase objective\n",
    "\n",
    "mod_bounds = [] # store upper bound, lower bound, difference btw the two\n",
    "objects = [] # store obj_LHS, obj_RHS, difference btw the two\n",
    "for i in ground:\n",
    "    if i in lib:\n",
    "        X_noi = [x for x in lib if x != i]\n",
    "        \n",
    "        up = opt.mod_upper(X_noi, opt.obj_LHS, lib, 4, dic)\n",
    "        down = opt.mod_lower(X_noi, opt.obj_RHS, perm, 4, dic, 100)\n",
    "        mod = up - down\n",
    "        \n",
    "        mod_bounds.append((up, down, mod))\n",
    "        assert obj_lst[-1] < mod\n",
    "        \n",
    "        obj_left = opt.obj_LHS(X_noi, 4, dic)\n",
    "        obj_right = opt.obj_RHS(X_noi, 4, dic, 100)\n",
    "        obj = obj_left - obj_right\n",
    "        \n",
    "        objects.append((obj_left, obj_right, obj))\n",
    "    else:\n",
    "        up = opt.mod_upper(lib + [i], opt.obj_LHS, lib, 4, dic)\n",
    "        down = opt.mod_lower(lib + [i], opt.obj_RHS, perm, 4, dic, 100)\n",
    "        mod = up - down\n",
    "        \n",
    "        mod_bounds.append((up, down, mod))\n",
    "        assert obj_lst[-1] < mod\n",
    "        \n",
    "        obj_left = opt.obj_LHS(lib + [i], 4, dic)\n",
    "        obj_right = opt.obj_RHS(lib + [i], 4, dic, 100)\n",
    "        obj = obj_left - obj_right\n",
    "        objects.append((obj_left, obj_right, obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(-5.5302), tensor(-114.4503), tensor(108.9200))\n",
      "(tensor(-6.9431), tensor(-4.3654), tensor(-2.5777))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-115.1706), tensor(109.6404))\n",
      "(tensor(-7.8266), tensor(-3.5279), tensor(-4.2987))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-116.1761), tensor(110.6459))\n",
      "(tensor(-5.7549), tensor(-2.8668), tensor(-2.8881))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-113.7682), tensor(108.2380))\n",
      "(tensor(-5.9185), tensor(-2.6678), tensor(-3.2507))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-114.3438), tensor(108.8135))\n",
      "(tensor(-5.6065), tensor(-3.5250), tensor(-2.0815))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-114.0227), tensor(108.4924))\n",
      "(tensor(-6.1104), tensor(-2.7543), tensor(-3.3561))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-114.2856), tensor(108.7554))\n",
      "(tensor(-6.0714), tensor(-3.0244), tensor(-3.0469))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-113.7682), tensor(108.2380))\n",
      "(tensor(-6.0059), tensor(-2.7073), tensor(-3.2987))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-114.1186), tensor(108.5883))\n",
      "(tensor(-5.6403), tensor(-3.5463), tensor(-2.0940))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-115.9352), tensor(110.4050))\n",
      "(tensor(-6.2632), tensor(-2.8232), tensor(-3.4400))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-114.1122), tensor(108.5820))\n",
      "(tensor(-5.5579), tensor(-2.7686), tensor(-2.7893))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-114.2025), tensor(108.6722))\n",
      "(tensor(-5.7441), tensor(-2.5892), tensor(-3.1549))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-113.7682), tensor(108.2380))\n",
      "(tensor(-5.7074), tensor(-3.5885), tensor(-2.1189))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-114.6942), tensor(109.1639))\n",
      "(tensor(-6.5987), tensor(-2.9744), tensor(-3.6242))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-113.7682), tensor(108.2380))\n",
      "(tensor(-5.6864), tensor(-2.8327), tensor(-2.8538))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-114.0466), tensor(108.5163))\n",
      "(tensor(-5.6718), tensor(-2.5566), tensor(-3.1152))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-113.7905), tensor(108.2603))\n",
      "(tensor(-6.9570), tensor(-4.3741), tensor(-2.5829))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-114.1698), tensor(108.6395))\n",
      "(tensor(-5.7286), tensor(-2.5822), tensor(-3.1464))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-125.9289), tensor(120.3986))\n",
      "(tensor(-7.5980), tensor(-3.7849), tensor(-3.8131))\n",
      "--------------------\n",
      "(tensor(-4.4226), tensor(-113.7301), tensor(109.3075))\n",
      "(tensor(-4.4226), tensor(-1.4469), tensor(-2.9757))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-114.7040), tensor(109.1738))\n",
      "(tensor(-6.5053), tensor(-4.0901), tensor(-2.4151))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-114.6478), tensor(109.1175))\n",
      "(tensor(-6.7160), tensor(-3.0273), tensor(-3.6887))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-115.0681), tensor(109.5379))\n",
      "(tensor(-5.7109), tensor(-2.8448), tensor(-2.8660))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-121.7643), tensor(116.2341))\n",
      "(tensor(-6.1655), tensor(-2.7792), tensor(-3.3863))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-113.7803), tensor(108.2500))\n",
      "(tensor(-5.6326), tensor(-3.5414), tensor(-2.0911))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-114.9897), tensor(109.4595))\n",
      "(tensor(-5.7054), tensor(-2.5718), tensor(-3.1336))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-113.8092), tensor(108.2790))\n",
      "(tensor(-5.8837), tensor(-2.9309), tensor(-2.9528))\n",
      "--------------------\n",
      "(tensor(-4.9420), tensor(-113.4434), tensor(108.5014))\n",
      "(tensor(-4.9420), tensor(-1.6168), tensor(-3.3252))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-117.9708), tensor(112.4406))\n",
      "(tensor(-5.9632), tensor(-3.7493), tensor(-2.2139))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-117.0688), tensor(111.5386))\n",
      "(tensor(-6.4777), tensor(-2.9199), tensor(-3.5578))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-121.1118), tensor(115.5816))\n",
      "(tensor(-6.1834), tensor(-3.0802), tensor(-3.1032))\n",
      "--------------------\n",
      "(tensor(-4.5214), tensor(-107.7876), tensor(103.2663))\n",
      "(tensor(-4.5214), tensor(-1.4792), tensor(-3.0422))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-113.8002), tensor(108.2699))\n",
      "(tensor(-5.5490), tensor(-3.4889), tensor(-2.0601))\n",
      "--------------------\n",
      "(tensor(-4.8173), tensor(-111.1897), tensor(106.3724))\n",
      "(tensor(-4.8173), tensor(-1.5760), tensor(-3.2413))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-113.7853), tensor(108.2550))\n",
      "(tensor(-5.5843), tensor(-2.7818), tensor(-2.8025))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-113.7871), tensor(108.2568))\n",
      "(tensor(-6.0259), tensor(-2.7162), tensor(-3.3096))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-114.2904), tensor(108.7601))\n",
      "(tensor(-6.1347), tensor(-3.8571), tensor(-2.2776))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-114.2871), tensor(108.7569))\n",
      "(tensor(-6.4698), tensor(-2.9163), tensor(-3.5534))\n",
      "--------------------\n",
      "(tensor(-3.5301), tensor(-92.6220), tensor(89.0919))\n",
      "(tensor(-3.5301), tensor(-0.8717), tensor(-2.6584))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-115.9971), tensor(110.4668))\n",
      "(tensor(-6.1942), tensor(-2.7921), tensor(-3.4021))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-120.1535), tensor(114.6232))\n",
      "(tensor(-5.9221), tensor(-3.7235), tensor(-2.1987))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-115.0027), tensor(109.4725))\n",
      "(tensor(-6.3896), tensor(-2.8802), tensor(-3.5094))\n",
      "--------------------\n",
      "(tensor(-4.8804), tensor(-113.7682), tensor(108.8878))\n",
      "(tensor(-4.8804), tensor(-1.2052), tensor(-3.6753))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-113.7682), tensor(108.2380))\n",
      "(tensor(-8.2448), tensor(-3.7164), tensor(-4.5284))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-113.7816), tensor(108.2513))\n",
      "(tensor(-5.6816), tensor(-3.5722), tensor(-2.1093))\n",
      "--------------------\n",
      "(tensor(-5.2305), tensor(-113.7682), tensor(108.5377))\n",
      "(tensor(-5.2305), tensor(-1.7112), tensor(-3.5194))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-114.0260), tensor(108.4958))\n",
      "(tensor(-5.6006), tensor(-2.7899), tensor(-2.8107))\n",
      "--------------------\n",
      "(tensor(-4.2993), tensor(-109.8301), tensor(105.5308))\n",
      "(tensor(-4.2993), tensor(-1.4065), tensor(-2.8928))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-115.2862), tensor(109.7560))\n",
      "(tensor(-5.7140), tensor(-3.5926), tensor(-2.1214))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-114.0851), tensor(108.5549))\n",
      "(tensor(-6.0262), tensor(-2.7164), tensor(-3.3098))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-115.4221), tensor(109.8918))\n",
      "(tensor(-5.7297), tensor(-2.8542), tensor(-2.8755))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-113.7774), tensor(108.2471))\n",
      "(tensor(-5.7039), tensor(-2.5711), tensor(-3.1328))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-115.7596), tensor(110.2294))\n",
      "(tensor(-5.7917), tensor(-3.6415), tensor(-2.1502))\n",
      "--------------------\n",
      "(tensor(-5.1749), tensor(-112.9087), tensor(107.7337))\n",
      "(tensor(-5.1749), tensor(-1.6930), tensor(-3.4820))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-113.7858), tensor(108.2556))\n",
      "(tensor(-5.7042), tensor(-2.8415), tensor(-2.8627))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-116.5139), tensor(110.9836))\n",
      "(tensor(-6.2287), tensor(-2.8076), tensor(-3.4210))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-113.7682), tensor(108.2380))\n",
      "(tensor(-5.6727), tensor(-3.5666), tensor(-2.1060))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-116.9424), tensor(111.4122))\n",
      "(tensor(-6.1180), tensor(-2.7577), tensor(-3.3602))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-114.6416), tensor(109.1113))\n",
      "(tensor(-5.7843), tensor(-2.8814), tensor(-2.9029))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-115.4453), tensor(109.9150))\n",
      "(tensor(-5.7618), tensor(-2.5972), tensor(-3.1646))\n",
      "--------------------\n",
      "(tensor(0.), tensor(-113.7676), tensor(113.7676))\n",
      "(tensor(0.), tensor(0.), tensor(0.))\n",
      "--------------------\n",
      "(tensor(-3.5838), tensor(-93.8180), tensor(90.2342))\n",
      "(tensor(-3.5838), tensor(-1.1724), tensor(-2.4113))\n",
      "--------------------\n",
      "(tensor(-2.6500), tensor(-55.9092), tensor(53.2592))\n",
      "(tensor(-2.6500), tensor(-0.6544), tensor(-1.9956))\n",
      "--------------------\n",
      "(tensor(-4.4316), tensor(-113.7271), tensor(109.2955))\n",
      "(tensor(-4.4316), tensor(-1.4498), tensor(-2.9818))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-123.5830), tensor(118.0528))\n",
      "(tensor(-6.6250), tensor(-4.1654), tensor(-2.4596))\n",
      "--------------------\n",
      "(tensor(-3.7978), tensor(-113.0496), tensor(109.2518))\n",
      "(tensor(-3.7978), tensor(-1.2424), tensor(-2.5553))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-113.9881), tensor(108.4578))\n",
      "(tensor(-5.5871), tensor(-2.7832), tensor(-2.8039))\n",
      "--------------------\n",
      "(tensor(-5.0344), tensor(-113.4473), tensor(108.4130))\n",
      "(tensor(-5.0344), tensor(-1.6470), tensor(-3.3874))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-114.3191), tensor(108.7889))\n",
      "(tensor(-5.6082), tensor(-3.5261), tensor(-2.0821))\n",
      "--------------------\n",
      "(tensor(-5.0469), tensor(-113.7563), tensor(108.7094))\n",
      "(tensor(-5.0469), tensor(-1.6511), tensor(-3.3958))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-118.3230), tensor(112.7928))\n",
      "(tensor(-6.2973), tensor(-3.1370), tensor(-3.1603))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-123.5263), tensor(117.9960))\n",
      "(tensor(-7.0537), tensor(-3.1795), tensor(-3.8741))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-115.0043), tensor(109.4741))\n",
      "(tensor(-5.5961), tensor(-3.5185), tensor(-2.0776))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-115.7068), tensor(110.1766))\n",
      "(tensor(-5.7899), tensor(-2.6099), tensor(-3.1800))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-115.9268), tensor(110.3966))\n",
      "(tensor(-5.7396), tensor(-2.8591), tensor(-2.8804))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-116.5167), tensor(110.9865))\n",
      "(tensor(-6.4578), tensor(-2.9109), tensor(-3.5469))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-113.9452), tensor(108.4149))\n",
      "(tensor(-5.8211), tensor(-3.6600), tensor(-2.1612))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-114.0631), tensor(108.5329))\n",
      "(tensor(-5.7114), tensor(-2.5745), tensor(-3.1369))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-114.5102), tensor(108.9799))\n",
      "(tensor(-5.6728), tensor(-2.8259), tensor(-2.8469))\n",
      "--------------------\n",
      "(tensor(-5.5302), tensor(-113.7682), tensor(108.2380))\n",
      "(tensor(-6.1299), tensor(-2.7631), tensor(-3.3668))\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "for mod, obj in zip(mod_bounds, objects):\n",
    "    print(mod)\n",
    "    print(obj)\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
