{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, makes predictions on a library of 160,000 PhoQ variants using GP and Matern Kernel then computes objective. Combines gp_ssm and objective_ssm notebooks. \n",
    "\n",
    "Includes functions that compute each of the three baselines:\n",
    "1. Baseline that creates optimal sequence from X's given optimal amino acids (those with max y-values) at each position out of the four possible positions in the wildtype sequence by fixing the three other positions, then continues onto the next position by fixing the best amino acid in the previous position.\n",
    "2. Baseline that creates optimal sequence from X's given optimal amino acids (those with max y-values) at each position out of the four possible positions in the wildtype sequence by fixing the three other positions, then takes the best amino acid at each position.\n",
    "3. Baseline that uses greedy algorithm to maximize objective. Starts out with best prediction then continues to add amino acids until objective stops increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import distributions as dist\n",
    "import itertools\n",
    "\n",
    "import operator\n",
    "import pickle\n",
    "import importlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style('white')\n",
    "sns.set_context('paper')\n",
    "# Plot adjustments:\n",
    "plt.rcParams.update({'ytick.labelsize': 15})\n",
    "plt.rcParams.update({'xtick.labelsize': 15})\n",
    "plt.rcParams.update({'axes.labelsize': 35})\n",
    "plt.rcParams.update({'legend.fontsize': 30})\n",
    "plt.rcParams.update({'axes.titlesize': 16})\n",
    "\n",
    "from gptorch import kernels, models\n",
    "import bases, helpers, opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../inputs/phoq.pkl', 'rb') as f:\n",
    "    t = pickle.load(f)\n",
    "\n",
    "X = t[0] # one-hot encoding of X\n",
    "T = t[1] # tokenized encoding of X\n",
    "y = t[2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_to_x = {} # dictionary of strings of aa with corresponding index in X\n",
    "for i, x in enumerate(X):\n",
    "    seq = helpers.decode_X(x)\n",
    "    seq_to_x[seq] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa: ['TDST', 'TDST', 'TDST', 'TRSQ', 'TRSQ', 'TRSQ', 'TDST', 'TDST', 'ADAR', 'ADAR', 'TDST', 'ADAT', 'ADCQ', 'ADCT', 'SDCT', 'FDCQ', 'ADCT', 'SDCT', 'TDSW', 'TSAW', 'TSLW', 'ASRW', 'THIW', 'ASIW']\n",
      "best baseline: ADAR\n",
      "y value: 1.7134569882257067\n",
      "global max: 1.788094549112096\n"
     ]
    }
   ],
   "source": [
    "# DET BASELINE_FIXED\n",
    "\n",
    "wt = helpers.decode_X(X[150614]) # wt as string\n",
    "seqs = bases.det_fixed(wt, X, y)\n",
    "print(\"aa: {}\".format(seqs))\n",
    "\n",
    "# find y-values corresponding to 24 possible baselines from baseline_fixed() --> take aa seq with max y\n",
    "\n",
    "seqs = list(set(seqs)) # remove duplicates\n",
    "X_decode = [helpers.decode_X(x) for x in X]\n",
    "ys_baseline = [y[X_decode.index(x)] for x in seqs]\n",
    "max_baseline = seqs[ys_baseline.index(max(ys_baseline))]\n",
    "\n",
    "y_seq1 = max(ys_baseline)\n",
    "print(\"best baseline: {}\".format(max_baseline))\n",
    "print(\"y value: {}\".format(y_seq1))\n",
    "print(\"global max: {}\".format(np.max(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa: TDCW\n",
      "y value: 1.0122630505442225\n",
      "global max: 1.788094549112096\n"
     ]
    }
   ],
   "source": [
    "# DET BASELINE_VARY\n",
    "\n",
    "wt = helpers.decode_X(X[150614])  # wt as string\n",
    "seq2 = bases.det_vary(wt, X, y)\n",
    "print(\"aa: {}\".format(seq2))\n",
    "\n",
    "y_seq2 = y[X_decode.index(seq2)]\n",
    "print(\"y value: {}\".format(y_seq2))\n",
    "print(\"global max: {}\".format(np.max(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500 of 500\tNLML: 37.3695\tsn: 0.179452\t"
     ]
    }
   ],
   "source": [
    "# BASELINE GREEDY ALGO\n",
    "\n",
    "np.random.seed(1)\n",
    "rand_inds = np.random.choice(len(X), 100, replace=True) # generate random indices for 100 X's to sample from\n",
    "X_train = X[rand_inds]\n",
    "y_train = y[rand_inds]\n",
    "X_test = X\n",
    "y_true = y\n",
    "\n",
    "dic, means = helpers.get_predictions(X_train, y_train, X_test, its=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('S', 0),\n",
       " ('S', 1),\n",
       " ('S', 2),\n",
       " ('L', 3),\n",
       " ('T', 1),\n",
       " ('C', 2),\n",
       " ('W', 3),\n",
       " ('A', 1),\n",
       " ('A', 0),\n",
       " ('I', 2),\n",
       " ('K', 3),\n",
       " ('C', 3),\n",
       " ('S', 3),\n",
       " ('G', 3),\n",
       " ('Y', 3)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = 4\n",
    "seed = helpers.get_seed(dic) # should seed in greedy algo still be best prediction?\n",
    "chosen, h = bases.greedy(dic, seed, 100, L)\n",
    "chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "helpers = importlib.reload(helpers)\n",
    "opt = importlib.reload(opt)\n",
    "\n",
    "seqs = helpers.seqs_from_set(chosen, 4)\n",
    "X_sampled = [X_train]\n",
    "y_sampled = [y_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##it should eventually come to a place where adding \n",
    "#items to the set doesn't improve the objective (or it's added everything to the set)\n",
    "\n",
    "n_start = 35\n",
    "max_its = 30\n",
    "rounds = 4\n",
    "L = 4\n",
    "n = 100\n",
    "\n",
    "libraries = []\n",
    "histories = []\n",
    "\n",
    "best_loss = 0.0\n",
    "best_X = None\n",
    "best_h = None\n",
    "    \n",
    "for rou in range(rounds):\n",
    "    print('Round %d' %rou)\n",
    "    dic, means = helpers.get_predictions(np.concatenate(X_sampled), np.concatenate(y_sampled), X_test, its=500)\n",
    "    print()\n",
    "    \n",
    "    #for i in range(max_its):\n",
    "    seed = helpers.get_seed(dic) # should seed in greedy algo still be best prediction?\n",
    "    chosen, h = bases.greedy(dic, seed, 100, L)\n",
    "    if h < best_loss:\n",
    "        best_loss = h\n",
    "        best_X = chosen\n",
    "        best_h = h\n",
    "        \n",
    "    libraries.append(chosen)\n",
    "    histories.append(h)\n",
    "    seqs = helpers.seqs_from_set(best_X, L)\n",
    "    inds = np.random.choice(len(seqs), n, replace=True)\n",
    "    sampled_seqs = [seqs[i] for i in inds]\n",
    "    inds = [seq_to_x[s] for s in sampled_seqs]\n",
    "    X_sampled.append(X[inds])\n",
    "    y_sampled.append(y[inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500 of 500\tNLML: 37.3695\tsn: 0.179452\t"
     ]
    }
   ],
   "source": [
    "## FIRST ITERATION\n",
    "n_start = 35\n",
    "max_its = 30\n",
    "rounds = 4\n",
    "L = 4\n",
    "n = 100\n",
    "\n",
    "best_loss = 0.0\n",
    "best_X = None\n",
    "best_h = None\n",
    "\n",
    "lst_ys = []\n",
    "libraries = []\n",
    "histories = []\n",
    "preds = [] # to keep track of predictions after each iteration through greedy algorithm\n",
    "\n",
    "dic, means = helpers.get_predictions(np.concatenate(X_sampled), np.concatenate(y_sampled), X_test, its=500)\n",
    "preds.append(means)\n",
    "\n",
    "seed = helpers.get_seed(dic) # should seed in greedy algo still be best prediction?\n",
    "chosen, h = bases.greedy(dic, seed, 100, L)\n",
    "if h < best_loss:\n",
    "    best_loss = h\n",
    "    best_X = chosen\n",
    "    best_h = h\n",
    "\n",
    "libraries.append(chosen)\n",
    "histories.append(h)\n",
    "seqs = helpers.seqs_from_set(chosen, L)\n",
    "inds = np.random.choice(len(seqs), n, replace=True)\n",
    "sampled_seqs = [seqs[i] for i in inds]\n",
    "inds = [seq_to_x[s] for s in sampled_seqs]\n",
    "X_sampled.append(X[inds])\n",
    "y_sampled.append(y[inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500 of 500\tNLML: -210.6028\tsn: 0.000001\t"
     ]
    }
   ],
   "source": [
    "## SECOND ITERATION\n",
    "dic, means = helpers.get_predictions(np.concatenate(X_sampled), np.concatenate(y_sampled), X_test, its=500)\n",
    "preds.append(means)\n",
    "\n",
    "seed = helpers.get_seed(dic) # should seed in greedy algo still be best prediction?\n",
    "chosen, h = bases.greedy(dic, seed, 100, L)\n",
    "if h < best_loss:\n",
    "    best_loss = h\n",
    "    best_X = chosen\n",
    "    best_h = h\n",
    "\n",
    "libraries.append(chosen)\n",
    "histories.append(h)\n",
    "seqs = helpers.seqs_from_set(chosen, L)\n",
    "inds = np.random.choice(len(seqs), n, replace=True)\n",
    "sampled_seqs = [seqs[i] for i in inds]\n",
    "inds = [seq_to_x[s] for s in sampled_seqs]\n",
    "X_sampled.append(X[inds])\n",
    "y_sampled.append(y[inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500 of 500\tNLML: -431.5349\tsn: 0.000001\t"
     ]
    }
   ],
   "source": [
    "## THIRD ITERATION\n",
    "dic, means = helpers.get_predictions(np.concatenate(X_sampled), np.concatenate(y_sampled), X_test, its=500)\n",
    "preds.append(means)\n",
    "\n",
    "seed = helpers.get_seed(dic) # should seed in greedy algo still be best prediction?\n",
    "chosen, h = bases.greedy(dic, seed, 100, L)\n",
    "if h < best_loss:\n",
    "    best_loss = h\n",
    "    best_X = chosen\n",
    "    best_h = h\n",
    "\n",
    "libraries.append(chosen)\n",
    "histories.append(h)\n",
    "seqs = helpers.seqs_from_set(chosen, L)\n",
    "inds = np.random.choice(len(seqs), n, replace=True)\n",
    "sampled_seqs = [seqs[i] for i in inds]\n",
    "inds = [seq_to_x[s] for s in sampled_seqs]\n",
    "X_sampled.append(X[inds])\n",
    "y_sampled.append(y[inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500 of 500\tNLML: -690.1974\tsn: 0.000001\t"
     ]
    }
   ],
   "source": [
    "## FOURTH ITERATION\n",
    "dic, means = helpers.get_predictions(np.concatenate(X_sampled), np.concatenate(y_sampled), X_test, its=500)\n",
    "preds.append(means)\n",
    "\n",
    "seed = helpers.get_seed(dic) # should seed in greedy algo still be best prediction?\n",
    "chosen, h = bases.greedy(dic, seed, 100, L)\n",
    "if h < best_loss:\n",
    "    best_loss = h\n",
    "    best_X = chosen\n",
    "    best_h = h\n",
    "\n",
    "libraries.append(chosen)\n",
    "histories.append(h)\n",
    "seqs = helpers.seqs_from_set(chosen, L)\n",
    "inds = np.random.choice(len(seqs), n, replace=True)\n",
    "sampled_seqs = [seqs[i] for i in inds]\n",
    "inds = [seq_to_x[s] for s in sampled_seqs]\n",
    "X_sampled.append(X[inds])\n",
    "y_sampled.append(y[inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500 of 500\tNLML: -850.4282\tsn: 0.000001\t"
     ]
    }
   ],
   "source": [
    "## FIFTH ITERATION\n",
    "dic, means = helpers.get_predictions(np.concatenate(X_sampled), np.concatenate(y_sampled), X_test, its=500, jitter=1e-5)\n",
    "preds.append(means)\n",
    "\n",
    "seed = helpers.get_seed(dic) # should seed in greedy algo still be best prediction?\n",
    "chosen, h = bases.greedy(dic, seed, 100, L)\n",
    "if h < best_loss:\n",
    "    best_loss = h\n",
    "    best_X = chosen\n",
    "    best_h = h\n",
    "\n",
    "libraries.append(chosen)\n",
    "histories.append(h)\n",
    "seqs = helpers.seqs_from_set(chosen, L)\n",
    "inds = np.random.choice(len(seqs), n, replace=True)\n",
    "sampled_seqs = [seqs[i] for i in inds]\n",
    "inds = [seq_to_x[s] for s in sampled_seqs]\n",
    "X_sampled.append(X[inds])\n",
    "y_sampled.append(y[inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 349 of 500\tNLML: -1162.0502\tsn: 0.000001\t"
     ]
    }
   ],
   "source": [
    "## SIXTH ITERATION\n",
    "dic, means = helpers.get_predictions(np.concatenate(X_sampled), np.concatenate(y_sampled), X_test, its=500, jitter=1e-5)\n",
    "preds.append(means)\n",
    "\n",
    "seed = helpers.get_seed(dic) # should seed in greedy algo still be best prediction?\n",
    "chosen, h = bases.greedy(dic, seed, 100, L)\n",
    "if h < best_loss:\n",
    "    best_loss = h\n",
    "    best_X = chosen\n",
    "    best_h = h\n",
    "\n",
    "libraries.append(chosen)\n",
    "histories.append(h)\n",
    "seqs = helpers.seqs_from_set(chosen, L)\n",
    "inds = np.random.choice(len(seqs), n, replace=True)\n",
    "sampled_seqs = [seqs[i] for i in inds]\n",
    "inds = [seq_to_x[s] for s in sampled_seqs]\n",
    "X_sampled.append(X[inds])\n",
    "y_sampled.append(y[inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## SEVENTH ITERATION\n",
    "dic, means = helpers.get_predictions(np.concatenate(X_sampled), np.concatenate(y_sampled), X_test, its=500, jitter=1e-5)\n",
    "preds.append(means)\n",
    "\n",
    "seed = helpers.get_seed(dic) # should seed in greedy algo still be best prediction?\n",
    "chosen, h = bases.greedy(dic, seed, 100, L)\n",
    "if h < best_loss:\n",
    "    best_loss = h\n",
    "    best_X = chosen\n",
    "    best_h = h\n",
    "\n",
    "libraries.append(chosen)\n",
    "histories.append(h)\n",
    "seqs = helpers.seqs_from_set(chosen, L)\n",
    "inds = np.random.choice(len(seqs), n, replace=True)\n",
    "sampled_seqs = [seqs[i] for i in inds]\n",
    "inds = [seq_to_x[s] for s in sampled_seqs]\n",
    "X_sampled.append(X[inds])\n",
    "y_sampled.append(y[inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## EIGHTH ITERATION\n",
    "dic, means = helpers.get_predictions(np.concatenate(X_sampled), np.concatenate(y_sampled), X_test, its=500, jitter=1e-5)\n",
    "preds.append(means)\n",
    "\n",
    "seed = helpers.get_seed(dic) # should seed in greedy algo still be best prediction?\n",
    "chosen, h = bases.greedy(dic, seed, 100, L)\n",
    "if h < best_loss:\n",
    "    best_loss = h\n",
    "    best_X = chosen\n",
    "    best_h = h\n",
    "\n",
    "libraries.append(chosen)\n",
    "histories.append(h)\n",
    "seqs = helpers.seqs_from_set(chosen, L)\n",
    "inds = np.random.choice(len(seqs), n, replace=True)\n",
    "sampled_seqs = [seqs[i] for i in inds]\n",
    "inds = [seq_to_x[s] for s in sampled_seqs]\n",
    "X_sampled.append(X[inds])\n",
    "y_sampled.append(y[inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## NINTH ITERATION\n",
    "dic, means = helpers.get_predictions(np.concatenate(X_sampled), np.concatenate(y_sampled), X_test, its=500, jitter=1e-5)\n",
    "preds.append(means)\n",
    "\n",
    "seed = helpers.get_seed(dic) # should seed in greedy algo still be best prediction?\n",
    "chosen, h = bases.greedy(dic, seed, 100, L)\n",
    "if h < best_loss:\n",
    "    best_loss = h\n",
    "    best_X = chosen\n",
    "    best_h = h\n",
    "\n",
    "libraries.append(chosen)\n",
    "histories.append(h)\n",
    "seqs = helpers.seqs_from_set(chosen, L)\n",
    "inds = np.random.choice(len(seqs), n, replace=True)\n",
    "sampled_seqs = [seqs[i] for i in inds]\n",
    "inds = [seq_to_x[s] for s in sampled_seqs]\n",
    "X_sampled.append(X[inds])\n",
    "y_sampled.append(y[inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TENTH ITERATION\n",
    "dic, means = helpers.get_predictions(np.concatenate(X_sampled), np.concatenate(y_sampled), X_test, its=500, jitter=1e-5)\n",
    "preds.append(means)\n",
    "\n",
    "seed = helpers.get_seed(dic) # should seed in greedy algo still be best prediction?\n",
    "chosen, h = bases.greedy(dic, seed, 100, L)\n",
    "if h < best_loss:\n",
    "    best_loss = h\n",
    "    best_X = chosen\n",
    "    best_h = h\n",
    "\n",
    "libraries.append(chosen)\n",
    "histories.append(h)\n",
    "seqs = helpers.seqs_from_set(chosen, L)\n",
    "inds = np.random.choice(len(seqs), n, replace=True)\n",
    "sampled_seqs = [seqs[i] for i in inds]\n",
    "inds = [seq_to_x[s] for s in sampled_seqs]\n",
    "X_sampled.append(X[inds])\n",
    "y_sampled.append(y[inds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot y vs mean error (for each iteration)\n",
    "\n",
    "errs = [helpers.get_mean_abs_err(X, y, mu, lib)[1] for mu, lib in zip(preds, libraries)]\n",
    "\n",
    "_ = plt.title(\"Mean absolute error for iterations of Greedy Algorithm\")\n",
    "_ = plt.plot(np.arange(len(errs)) + 1, errs, marker='o', linestyle='none')\n",
    "\n",
    "_ = plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # Plot mean error for y's vs. y's sorted (for each iteration)\n",
    "\n",
    "abs_errs = [helpers.get_mean_abs_err(X, y, mu, lib)[0] for mu, lib in zip(preds, libraries)]\n",
    "_ = plt.title(\"Absolute error vs y's tested on for iterations of Greedy Algorithm\")\n",
    "\n",
    "for err in abs_errs: # each err is a tuple of y_test, abs errs\n",
    "    sorted_ind = sorted(range(len(err[0])), key=lambda k: err[0][k]) # get indexes of y sorted\n",
    "    y_sort = np.sort(err[0]) # sort y\n",
    "    err_sort = [err[1][i] for i in sorted_ind]\n",
    "    _ = plt.plot(y_sort, err_sort, marker='.')\n",
    "\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ecdf(data):\n",
    "    \"\"\"Compute ECDF for a one-dimensional array of measurements.\"\"\"\n",
    "    # Number of data points: n\n",
    "    n = len(data)\n",
    "\n",
    "    # x-data for the ECDF: x\n",
    "    x = np.sort(data)\n",
    "\n",
    "    # y-data for the ECDF: y\n",
    "    y = np.arange(1, n + 1) / n\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute ECDF\n",
    "x_val, y_val = ecdf(y)\n",
    "\n",
    "# Generate plot\n",
    "_ = plt.title(\"ECDF of y's and deterministic baselines\")\n",
    "_ = plt.plot(x_val, y_val, marker='.', linestyle='none', label=\"orig y's\")\n",
    "_ = plt.plot(y_seq1, y_val[np.argwhere(x_val == y_seq1)[0][0]], marker='o', label='baseline_fixed')\n",
    "_ = plt.plot(y_seq2, y_val[np.argwhere(x_val == y_seq2)[0][0]], marker='o', label='baseline_vary')\n",
    "_ = plt.legend(loc='upper center', bbox_to_anchor=(1.45, 0.8), shadow=True, ncol=1)\n",
    "\n",
    "# Label the axes\n",
    "_ = plt.ylabel('ECDF')\n",
    "_ = plt.xlabel('y')\n",
    "\n",
    "# Display the plot\n",
    "_ = plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot Greedy algorithm baseline with deterministic baselines too\n",
    "\n",
    "d = {'Iterations': [], 'Sampled ys': []}\n",
    "\n",
    "for i in range(len(y_sampled)):\n",
    "    for j in y_sampled[i]:\n",
    "        d['Iterations'].append(i)\n",
    "        d['Sampled ys'].append(j)\n",
    "    \n",
    "df = pd.DataFrame(data=d) # make dataframe of sampled ys to plot on swarmplot\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "_ = plt.title('Baselines: deterministic and Greedy algorithm')\n",
    "ax = sns.swarmplot(x=\"Iterations\", y=\"Sampled ys\", data=df) # swamplot allows for jitter in displaying cluster of ys\n",
    "_ = ax.axhline(y_seq1, color='purple', label='baseline_fixed')\n",
    "_ = ax.axhline(y_seq2, color='black', label='baseline_vary')\n",
    "_ = plt.legend(loc='upper center', bbox_to_anchor=(1.45, 0.8), shadow=True, ncol=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
