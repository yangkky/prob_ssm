{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implements algorithm 3 (ModMod) from Algorithms for \"Approx Min of the Difference Between Submodular Fncs with Applications.\"\n",
    "\n",
    "For prob_ssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import distributions as dist\n",
    "\n",
    "import itertools\n",
    "import pickle\n",
    "import operator\n",
    "\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style('white')\n",
    "sns.set_context('paper')\n",
    "# Plot adjustments:\n",
    "plt.rcParams.update({'ytick.labelsize': 15})\n",
    "plt.rcParams.update({'xtick.labelsize': 15})\n",
    "plt.rcParams.update({'axes.labelsize': 35})\n",
    "plt.rcParams.update({'legend.fontsize': 30})\n",
    "plt.rcParams.update({'axes.titlesize': 16})\n",
    "\n",
    "from gptorch import kernels, models\n",
    "\n",
    "import helpers, opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../inputs/phoq.pkl', 'rb') as f:\n",
    "    t = pickle.load(f)\n",
    "\n",
    "X = t[0] # one-hot encoding of X\n",
    "T = t[1] # tokenized encoding of X\n",
    "y = t[2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "rand_inds = np.random.choice(len(X), 100, replace=True) # generate random indices for 100 X's to sample from\n",
    "X_train = X[rand_inds]\n",
    "y_train = y[rand_inds]\n",
    "X_test = X\n",
    "y_true = y\n",
    "\n",
    "dic = helpers.get_predictions(X_train, y_train, X_test, its=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ground = [(aa, i) for aa in 'ARNDCQEGHILKMFPSTWYV' for i in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(4195)\n",
    "center = np.random.choice(len(ground), 35, replace=False)\n",
    "center = [ground[c] for c in center]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, h = opt.mod_mod(ground, opt.obj_LHS, opt.obj_RHS, center, fn_args=(4, dic), g_args=(4, dic, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampler_full_obj(lib, mu, K, tau, its=10, n=100):\n",
    "    \"\"\" Takes in a library (list of tuples with aa and positions),\n",
    "    full mean (a dictionary mapping sequence, a string, to its mean)\n",
    "    and covariance, threshold, number of iterations, and\n",
    "    batch size. \n",
    "    \n",
    "    Samples from full objective, and returns the number sampled that is \n",
    "    greater than tau (threshold). \"\"\"\n",
    "    \n",
    "    num_greater = []\n",
    "    lib = np.array(helpers.seqs_from_set(lib, 4)) # extract variants from library\n",
    "    \n",
    "    for _ in range(its):\n",
    "        rand_inds = np.random.choice(len(lib), n, replace=True) # generate random indices\n",
    "        rand_inds = np.unique(rand_inds) # remove duplicates\n",
    "        chosen = lib[rand_inds]\n",
    "        means_chosen = np.array([mu[key] for key in mu if key in chosen])\n",
    "        inds = np.array([list(mu.values()).index(m) for m in means_chosen])\n",
    "        sample = np.random.multivariate_normal(means_chosen, K[inds, inds]) # (n, ) vector\n",
    "        num_greater.append(np.sum(s > tau))\n",
    "    \n",
    "    return num_greater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 500 of 500\tNLML: 37.3695\tsn: 0.179451\t"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "rand_inds = np.random.choice(len(X), 100, replace=True) # generate random indices for 100 X's to sample from\n",
    "X_train = X[rand_inds]\n",
    "y_train = y[rand_inds]\n",
    "X_test = X\n",
    "y_true = y\n",
    "\n",
    "dic, means = helpers.get_predictions(X_train, y_train, X_test, its=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "$ Torch: not enough memory: you tried to allocate 95GB. Buy new RAM! at ..\\src\\TH\\THGeneral.c:218",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-23ff13d76cb9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mke\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkernels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaternKernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcov\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 491\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    492\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\prob_ssm\\code\\gptorch\\kernels.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X1, X2, hypers)\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[0mK\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mn\u001b[0m \u001b[0mx\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \"\"\"\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m         \u001b[0mD_L\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mell\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[0msqrt5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5.0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Python Scripts\\prob_ssm\\code\\gptorch\\kernels.py\u001b[0m in \u001b[0;36mcdist\u001b[1;34m(X1, X2, squared)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mB\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 95GB. Buy new RAM! at ..\\src\\TH\\THGeneral.c:218"
     ]
    }
   ],
   "source": [
    "ke = kernels.MaternKernel()\n",
    "cov = ke(torch.Tensor(X), torch.Tensor(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lib = [('F', 3), ('V', 1), ('P', 2), ('A', 0), ('R', 0), ('Q', 3)]\n",
    "tau = helpers.get_seed(dic)\n",
    "sampler_full_obj(lib, means, cov, tau)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
