{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, makes predictions on a library of 160,000 PhoQ variants using GP and Matern Kernel then computes objective. Combines gp_ssm and objective_ssm notebooks. \n",
    "\n",
    "Includes functions that compute each of the three baselines:\n",
    "1. Baseline that creates optimal sequence from X's given optimal amino acids (those with max y-values) at each position out of the four possible positions in the wildtype sequence by fixing the three other positions, then continues onto the next position by fixing the best amino acid in the previous position.\n",
    "2. Baseline that creates optimal sequence from X's given optimal amino acids (those with max y-values) at each position out of the four possible positions in the wildtype sequence by fixing the three other positions, then takes the best amino acid at each position.\n",
    "3. Baseline that uses greedy algorithm to maximize objective. Starts out with best prediction then continues to add amino acids until objective stops increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import distributions as dist\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "from scipy.stats import norm\n",
    "import operator\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style('white')\n",
    "sns.set_context('paper')\n",
    "# Plot adjustments:\n",
    "plt.rcParams.update({'ytick.labelsize': 15})\n",
    "plt.rcParams.update({'xtick.labelsize': 15})\n",
    "plt.rcParams.update({'axes.labelsize': 35})\n",
    "plt.rcParams.update({'legend.fontsize': 30})\n",
    "plt.rcParams.update({'axes.titlesize': 16})\n",
    "\n",
    "from gptorch import kernels, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../inputs/phoq.pkl', 'rb') as f:\n",
    "    t = pickle.load(f)\n",
    "\n",
    "X = t[0] # one-hot encoding of X\n",
    "T = t[1] # tokenized encoding of X\n",
    "y = t[2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_X(X):\n",
    "    \"\"\" Takes in one-hot encoding X and decodes it to\n",
    "    return a string of four amino acids. \"\"\"\n",
    "    \n",
    "    amino_acids = 'ARNDCQEGHILKMFPSTWYV'\n",
    "    \n",
    "    pos_X = [i for i, x in enumerate(X) if x == 1.0] # positions of amino acids\n",
    "    pos_X = [(p - 20 * i) for i, p in enumerate(pos_X)] # make sure indexing is same as in str amino_acids\n",
    "    aa_X = [amino_acids[p] for i, p in enumerate(pos_X)] # amino acid chars in X\n",
    "    return ''.join(aa_X)\n",
    "\n",
    "# test on AWSS\n",
    "# decode_X([ 1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "#         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "#         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,\n",
    "#         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "#         0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
    "#         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n",
    "#         0.,  0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## UPDATED VERSION OF GP_train() method\n",
    "\n",
    "def get_predictions(X_train, y_train, X_test, its=500):\n",
    "    \"\"\"\n",
    "    Train GP regressor on X_train and y_train. \n",
    "    Predict mean and std for X_test. \n",
    "    Return P(y > y_train_max) as dictionary eg 'AGHU': 0.78\n",
    "    NB: for X_test in X_train, P ~= 0\n",
    "    Be careful with normalization\n",
    "    \n",
    "    Expects X_train, y_train, and X_test as np.arrays\n",
    "    \"\"\"\n",
    "    \n",
    "    ke = kernels.MaternKernel()\n",
    "    mo = models.GPRegressor(ke)\n",
    "    \n",
    "    # make data into tensors\n",
    "    X_train = torch.Tensor(X_train)\n",
    "    X_test = torch.Tensor(np.array(X_test))\n",
    "    y_train_scaled = (np.array(y_train) - np.mean(np.array(y_train))) / np.std(np.array(y_train)) # scale y_train\n",
    "    y_train_scaled = torch.Tensor(y_train_scaled.reshape(len(y_train_scaled), 1)).double()\n",
    "    \n",
    "    his = mo.fit(X_train, y_train_scaled, its=its) # fit model with training set\n",
    "    \n",
    "    # make predictions\n",
    "    dic = {} # use dictionary to store probs\n",
    "    ind = 0 # index for feeding in batches of X_test\n",
    "    tau = y_train_scaled.max().float()\n",
    "    \n",
    "    for i in range(1000, len(X) + 1000, 1000):\n",
    "        mu, var = mo.forward(X_test[ind:i]) # make predictions\n",
    "        std = torch.sqrt(var.diag())\n",
    "        mu = mu.squeeze()\n",
    "        prob = 1 - dist.Normal(mu, std).cdf(tau) # compute probabilities for all means, stds\n",
    "\n",
    "        for j, p in enumerate(prob):\n",
    "            seq = decode_X(X_test[ind:i][j])\n",
    "            dic[seq] = p # store prob for each seq\n",
    "\n",
    "        ind = i\n",
    "        \n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Iteration 1 of 10\tNLML: 45.3735\t\r",
      "Iteration 2 of 10\tNLML: 44.1491\t\r",
      "Iteration 3 of 10\tNLML: 43.1219\t\r",
      "Iteration 4 of 10\tNLML: 42.1918\t\r",
      "Iteration 5 of 10\tNLML: 41.3986\t\r",
      "Iteration 6 of 10\tNLML: 40.8094\t\r",
      "Iteration 7 of 10\tNLML: 40.4363\t\r",
      "Iteration 8 of 10\tNLML: 40.2570\t\r",
      "Iteration 9 of 10\tNLML: 40.2296\t\r",
      "Iteration 10 of 10\tNLML: 40.2686\t"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "rand_inds = np.random.choice(len(X), 100, replace=True) # generate random indices for 100 X's to sample from\n",
    "X_train = X[rand_inds]\n",
    "y_train = y[rand_inds]\n",
    "X_test = X\n",
    "y_true = y\n",
    "\n",
    "dic = get_predictions(X_train, y_train, X_test, its=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use GP to make predictions - returns dictionary of means and stds\n",
    "\n",
    "def GP_train(X, y, n):\n",
    "    \"\"\" GP that uses Matern Kernel and trains on n number of samples--where n is the batch \n",
    "    size--of examples from X and makes predictions on the rest of X. \"\"\"\n",
    "    \n",
    "    ke = kernels.MaternKernel()\n",
    "    mo = models.GPRegressor(ke)\n",
    "\n",
    "    np.random.seed(1)\n",
    "    rand_inds = np.random.choice(len(X), n, replace=True) # generate random indices for 100 X's to sample from\n",
    "    test_inds = [i for i in np.arange(len(X)) if i not in rand_inds]\n",
    "    X_train = X[rand_inds]\n",
    "    y_train = y[rand_inds]\n",
    "    X_test = X[test_inds]\n",
    "    y_true = y[test_inds]\n",
    "\n",
    "    # make data into tensors\n",
    "    X_train = torch.Tensor(X_train)\n",
    "    X_test = torch.Tensor(np.array(X_test))\n",
    "    y_train_scaled = (np.array(y_train) - np.mean(np.array(y_train))) / np.std(np.array(y_train)) # scale y_train\n",
    "    y_train_scaled = torch.Tensor(y_train_scaled.reshape(len(y_train_scaled), 1)).double()\n",
    "\n",
    "    his = mo.fit(X_train, y_train_scaled, its=500) # fit model with training set\n",
    "    \n",
    "    # make predictions\n",
    "    dic = {} # use dictionary to store means, stds\n",
    "    ind = 0\n",
    "    for i in range(1000, len(X) + 1000, 1000):\n",
    "        mu_scaled, var = mo.forward(X_test[ind:i]) # make predictions\n",
    "        mu = mu_scaled * np.std(np.array(y_train)) + np.mean(np.array(y_train)) # unscale predictions\n",
    "        std = np.sqrt(np.diag(var.detach().numpy())) * np.std(np.array(y_train))\n",
    "        \n",
    "        for j, m in enumerate(mu):\n",
    "            dic[X_test[ind:i][j]] = (m, std[j]) # store means, stds\n",
    "\n",
    "        ind = i\n",
    "        \n",
    "    return dic\n",
    "#     # used for list slicing of means and stds - split into two lists to be dumped into two pickle files\n",
    "#     half = (len(X) - n) // 2\n",
    "#     full = len(X) - n\n",
    "    \n",
    "#     # write results out to pickle files\n",
    "#     with open('GP_ssm_results1.pkl', 'wb') as f:\n",
    "#         pickle.dump((means[0:half], stds[0:half], y_true[0:half], max(y)), f) # pass in tau (best experimental value) as well\n",
    "\n",
    "#     with open('GP_ssm_results2.pkl', 'wb') as f:\n",
    "#         pickle.dump((means[half:full], stds[half:full], y_true[half:full]), f)\n",
    "    \n",
    "dic = GP_train(X, y, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Computing objective\n",
    "\n",
    "def objective(X, probs, n):\n",
    "    \"\"\" Takes in library X, probabilities, and batch size n.\n",
    "    \n",
    "    Expects X to be a list of tuples, and probs to be a dictionary.\n",
    "    \n",
    "    Returns objective to be maximized. \"\"\"\n",
    "    \n",
    "    N = 1 # represents the product of sequence of # aas at each position\n",
    "    for i in X:\n",
    "        N *= len(i)\n",
    "    \n",
    "    # filter thru probs to find prob of x's in X\n",
    "    X.sort(key=lambda tup: tup[1])\n",
    "\n",
    "    X_str = [[tup[0] for i, tup in enumerate(X) if tup[1] == j] for j in range(4)] # generate list of lists of strings\n",
    "    X_str = [''.join(s) for s in itertools.product(*X_str)] # generate list of strings of 4 aa seqs\n",
    "\n",
    "    p = torch.Tensor([probs[key] for key in X_str])\n",
    "    obj = torch.sum(p) * (1 - (1 - 1 / N) ** n)\n",
    "    \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_fixed(wt, X, y):\n",
    "    \"\"\" Takes in wildtype sequence, X, and y to compute baseline that creates \n",
    "    optimal sequence from X's given optimal amino acids (those with max y-values) \n",
    "    at each position out of the four possible positions in the wildtype sequence \n",
    "    by fixing the three other positions, then continues onto the next position in\n",
    "    the wildtype sequence by fixing the best amino acid in the previous position.\n",
    "    So the fixed substring is not necessarily a fixed substring of the wildtype sequence.\n",
    "    \n",
    "    Note: wildtype sequence expected as one-hot encoding. X expected as an array or list of\n",
    "    one-hot encodings.\n",
    "    \n",
    "    Returns optimal untested variant. \"\"\"  \n",
    "    \n",
    "    inds = [i for i, num in enumerate(wt) if num == 1.0] # store initial indices of four positions with amino acids\n",
    "    baseline = np.zeros((80,)) # stores baseline untested variant to be returned\n",
    "\n",
    "    for i in range(4):\n",
    "        fixed = list(inds[0:i] + inds[i + 1:len(inds)]) # list of 3 fixed amino acids in each iteration through wt seq\n",
    "\n",
    "        index = [] # index of xs in X\n",
    "        for j, x in enumerate(X):\n",
    "            in_lst = True\n",
    "            for m in fixed:\n",
    "                if x[m] != 1.0:\n",
    "                    in_lst = False\n",
    "            if in_lst == True:\n",
    "                index.append(j)\n",
    "                \n",
    "        ys = [y[j] for j in index] # stores y values of x's in X with those 3 fixed amino acids\n",
    "\n",
    "        max_ind = np.where(ys==max(ys))[0][0] # takes first occurrence of index with maximum y value\n",
    "\n",
    "        # store amino acid in position being varied in baseline\n",
    "        baseline[(i * 20):(i * 20 + 20)] = X[index[max_ind]][(i * 20):(i * 20 + 20)]\n",
    "\n",
    "        # update inds to include index of new amino acid stored in baseline\n",
    "        for j, num in enumerate(X[index[max_ind]][(i * 20):(i * 20 + 20)]):\n",
    "            if num == 1.0:\n",
    "                inds[i] = j + i * 20\n",
    "                break\n",
    "    \n",
    "    return baseline\n",
    "                \n",
    "seq = baseline_fixed(X[150614], X, y)\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_vary(wt, X, y):\n",
    "    \"\"\" Takes in wildtype sequence, X, and y to compute baseline that creates \n",
    "    optimal sequence from X's given optimal amino acids (those with max y-values) at each \n",
    "    position out of the four possible positions in the wildtype sequence by fixing the three\n",
    "    other positions, then takes the best amino acid at each position. The fixed substring\n",
    "    in each iteration is a substring of the wildtype sequence.\n",
    "    \n",
    "    Note: wildtype sequence expected as one-hot encoding. X expected as an array or list of\n",
    "    one-hot encodings.\n",
    "    \n",
    "    Returns optimal untested variant. \"\"\"\n",
    "    \n",
    "    inds = [i for i, num in enumerate(wt) if num == 1.0] # store indices of four positions with amino acids\n",
    "    baseline = np.zeros((80,)) # stores baseline untested variant to be returned\n",
    "    \n",
    "    for i in range(4): # vary amino acid in each position\n",
    "        fixed = list(inds[0:i] + inds[i + 1:len(inds)]) # list of 3 fixed amino acids in each iteration through wt seq\n",
    "        \n",
    "        xs_inds = [] # index of x's in X with those 3 fixed amino acids\n",
    "        for j, x in enumerate(X):\n",
    "            in_lst = True\n",
    "            for m in fixed:\n",
    "                if x[m] != 1.0:\n",
    "                    in_lst = False\n",
    "            if in_lst:\n",
    "                xs_inds.append(j)\n",
    "        \n",
    "        ys = [y[j] for j in xs_inds] # stores y values of x's in X with those 3 fixed amino acids\n",
    "        max_ind = np.where(ys==max(ys))[0][0] # takes first occurrence of index with maximum y value\n",
    "        \n",
    "        # store amino acid in position being varied in baseline\n",
    "        baseline[(i * 20):(i * 20 + 20)] = X[xs_inds[max_ind]][(i * 20):(i * 20 + 20)] \n",
    "    \n",
    "    return baseline\n",
    "\n",
    "seq = baseline_vary(X[150614], X, y)\n",
    "print(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avail_aa(X):\n",
    "    \"\"\" Takes in a library X and returns a list of tuples of the available amino acids \n",
    "    at each position that can be added to the library. \"\"\"\n",
    "    \n",
    "    amino_acids = 'ARNDCQEGHILKMFPSTWYV'\n",
    "    return [(aa, i) for i in range(4) for aa in amino_acids if (aa, i) not in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def baseline_greedy(probs, seed, n):\n",
    "    \"\"\" Takes in probabilities, seed (the best prediction), and batch size\n",
    "    to create baseline optimal library using the Greedy algorithm. The algo \n",
    "    starts out with the seed then continues to add amino acids until obj\n",
    "    stops increasing.\n",
    "    \n",
    "    Note: probs expected as a dictionary, and seed expected as list of tuples.\n",
    "    \n",
    "    Returns optimal untested library. \"\"\"\n",
    "    \n",
    "    X = seed # library X starts with seed\n",
    "    \n",
    "    obj = objective(X, probs, n)\n",
    "    aa = avail_aa(X) # determine available/unincluded amino acids at each position of X\n",
    "    \n",
    "    while True:\n",
    "        lst = [objective(X + [a], probs, n) for a in aa] # lst of obj's for library w each available aa added\n",
    "        index, obj_next = max(enumerate(lst), key=operator.itemgetter(1)) # determine which aa maximizes obj\n",
    "        \n",
    "        if obj_next < obj: # if obj stops increasing, exit\n",
    "            break\n",
    "        else:\n",
    "            X.append(aa[index]) # add aa that maximizes obj to X\n",
    "            obj = obj_next\n",
    "            aa.remove(aa[index])\n",
    "            \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_seed(probs):\n",
    "    \"\"\" Takes in a dictionary of amino acids to probabilities as\n",
    "    generated by the get_predictions() function, and returns the \n",
    "    seed (the four amino acid seq with the best prediction, aka the \n",
    "    highest probabilitiy). \n",
    "    \n",
    "    Returns a list of tuples representing the seed.\n",
    "    \n",
    "    Currently, 'SSSG' is the seed. \"\"\"\n",
    "    \n",
    "    seq = max(probs.items(), key=operator.itemgetter(1))[0]\n",
    "    return [(aa, i) for aa, i in zip(seq, range(4))]\n",
    "\n",
    "seed = get_seed(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('S', 0), ('S', 1), ('S', 2), ('G', 3)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('S', 0), ('S', 1), ('S', 2), ('G', 3), ('L', 3), ('T', 1), ('C', 2)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_greedy(dic, seed, 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
